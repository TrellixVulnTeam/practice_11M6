{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "# Problem 12: Major League Baseball"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "This part of the exam will test your skills maneuvering in Pandas, as well as your ability to think of ways to improve computing and memory efficiency.\n",
                "\n",
                "The dataset used in these exercises, [\"Offensive Baseball Stats Through 2016\"](https:\/\/www.kaggle.com\/baseballstatsonline\/offensive-baseball-stats-through-2016), Version 1, is from Kaggle user baseballstatsonline.com. The dataset is a fairly rich set of players and statistics, but for the purposes of these exercises you do not need to know anything in particular about the columns' meaning unless it is otherwise explained below. The dataset has been modified slightly for the purpose of some exercises. \n",
                "\n",
                "Run the following code cell to download the data and create some necessary functions. Good luck!\n",
                "\n",
                "**Note:** If you are running this notebook locally please make sure you run the same version of pandas as in Vocareum enviroment."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "from cse6040utils import canonicalize_tibble, tibbles_are_equivalent    \n",
                "\n",
                "def get_data_path(filebase):\n",
                "    return f\".\/resource\/asnlib\/publicdata\/mlb\/{filebase}\"\n",
                "\n",
                "baseball = pd.read_csv(get_data_path('mlb_off_stats_modified.csv'),header=0)\n",
                "baseball_test = baseball.iloc[np.arange(1, baseball.shape[0], 200)]\n",
                "baseball.head(5)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "First things first, let's delete unnecessary columns.\n",
                "\n",
                "**Exercise 0** (1 point): Complete the `remove_redundant_columns` function that takes dataframe `df` and returns a _**new**_ dataframe  _excluding_ the following columns:\n",
                "- Any column with the word 'Career' in it's name\n",
                "- Any column with the string 'birth' in it's name\n",
                "- 200HitSeason, Decade, Player Name, name, park, lgID, bats\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "collapsed": true
            },
            "outputs": [],
            "source": [
                "def remove_redundant_columns(df):\n",
                "    ###\n",
                "    ### YOUR CODE HERE\n",
                "    ###\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "To test your solution we have created a data frame `baseball_test` which is a much smaller sample of the orginial dataframe `baseball`. We also provided how the output for `remove_redundant_columns(baseball_test)` should look like in data-frame `df_ex0_soln_instructor`. \n",
                "\n",
                "**Note**: The below test case is designed just for the purpose of debugging and will not be used for grading. "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "nbgrader": {
                    "grade": true,
                    "grade_id": "remove_redundant_columns_dummy",
                    "locked": true,
                    "points": "0",
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "# (0 Points) `remove_redundant_columns_dummy`: Test cell 1\n",
                "from pandas.util.testing import assert_frame_equal\n",
                "\n",
                "df_ex0_soln_instructor = canonicalize_tibble(pd.read_csv(get_data_path('ex0_soln.csv')))\n",
                "df_ex0_soln_yours = canonicalize_tibble(remove_redundant_columns(baseball_test))\n",
                "\n",
                "assert type(df_ex0_soln_yours) == type(df_ex0_soln_instructor), 'Your output does not return a pandas dataframe'\n",
                "assert_frame_equal(df_ex0_soln_instructor, df_ex0_soln_yours)\n",
                "\n",
                "print('Passed!')\n",
                "\n",
                "del df_ex0_soln_instructor\n",
                "del df_ex0_soln_yours"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "Testing your solution on the original dataframe\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "nbgrader": {
                    "grade": true,
                    "grade_id": "remove_redundant_columns",
                    "locked": true,
                    "points": "1",
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "# (1 Point) `remove_redundant_columns`: Test cell 2\n",
                "assert tibbles_are_equivalent(remove_redundant_columns(baseball), -8278288771535832348), \"Tibbles don't match!\" \n",
                "print(\"Passed!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "Great! If the above test case passed then let's remove columns from the original dataset `df` using `remove_redundant_columns(baseball)`"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "baseball_test = remove_redundant_columns(baseball_test)\n",
                "baseball = remove_redundant_columns(baseball)\n",
                "baseball.shape"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "#### Shrinking the dataset.\n",
                "\n",
                "**Exercise 1** (1 point). Write a function `shrink_data()` which takes the dataframe `df` and returns a **new** dataframe where:\n",
                "\n",
                "* the column `yearID` should be converted to `pandas datetime` format; **and**\n",
                "* only rows such that `yearID` is from 2000 (inclusive) to 2016 (inclusive) are returned.\n",
                "\n",
                "> Hint: Regarding the first condition, see [`pandas.to_datetime()`](https:\/\/pandas.pydata.org\/pandas-docs\/stable\/generated\/pandas.to_datetime.html)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "collapsed": true
            },
            "outputs": [],
            "source": [
                "def shrink_data(df):\n",
                "    ###\n",
                "    ### YOUR CODE HERE\n",
                "    ###\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "The test below will test your solution on a the smaller sample `baseball_test`. \n",
                "\n",
                "**Note**: The below test case is designed just for the purpose of debugging and will not be used for grading. "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "nbgrader": {
                    "grade": true,
                    "grade_id": "shrink_data_dummy",
                    "locked": true,
                    "points": "0",
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "# (0 Points) `shrink_data_dummy`:  Test cell 1\n",
                "\n",
                "from pandas.util.testing import assert_frame_equal\n",
                "\n",
                "df_ex1_soln_instructor = canonicalize_tibble(pd.read_csv(get_data_path('ex1_soln.csv'), parse_dates=['yearID']))\n",
                "df_ex1_soln_yours = canonicalize_tibble(shrink_data(baseball_test))\n",
                "\n",
                "assert type(df_ex1_soln_yours) == type(df_ex1_soln_instructor), 'Your output does not return a pandas dataframe'\n",
                "assert_frame_equal(df_ex1_soln_instructor, df_ex1_soln_yours)\n",
                "\n",
                "print('Passed!')\n",
                "del df_ex1_soln_instructor\n",
                "del df_ex1_soln_yours"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "Testing solution on original dataframe"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "nbgrader": {
                    "grade": true,
                    "grade_id": "shrink_data",
                    "locked": true,
                    "points": "1",
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "# (1 Points) `shrink_data`: Test cell\n",
                "assert tibbles_are_equivalent(shrink_data(baseball), 1828659959833542576), \"Tibbles don't match!\" \n",
                "print(\"Passed!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "Let's shrink the orginial dataframe now."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "baseball_test = shrink_data(baseball_test)\n",
                "baseball = shrink_data(baseball)\n",
                "baseball.shape"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "Several players appear in the dataset more than once. This is because they played for one team, then were traded or moved to another. Currently, the combination of `playerID`, `stint`, and `teamID` is unique within each row. We want to transform this into a dataset that contains the all _minimum_ characteristics of each player over all the teams and stints the player had.\n",
                "\n",
                "**Exercise 2** (3 points). Complete the function `transform_baseball_data(df)` and return a **new** dataframe such that, for each unique player (`playerID`):\n",
                "- only the earliest `yearID` is retained;\n",
                "- only the _lowest_ value of every numerical column is retained;\n",
                "- the columns `stint` and `teamID` are not retained;\n",
                "- after tranformation the numerical values are rounded to nearest 10 and converted to integer. For example, the value 15.33 rounded to nearest 10 is 20, and the value 14.999 is rounded to 10. For cases like 5, 15, 25, etc., such a value `v` would be the same as that produced by `round(v, -1)` in standard Python.\n",
                "\n",
                "The final data frame will have one row per unique player with the columns retained and transformed as outlined above.\n",
                "\n",
                "A natural way to start is to group the data frame `df` by `playerID`. However, for your final result, be sure that `playerID` is **not** the index. (That is, be sure your final result is a tibble.)\n",
                "\n",
                "> Hint: A relatively clean solution may be had by exploiting features of the [`.agg()` method](https:\/\/pandas.pydata.org\/pandas-docs\/stable\/generated\/pandas.core.groupby.DataFrameGroupBy.agg.html) available for `.groupby()` objects produced when called on `DataFrame` objects."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "collapsed": true
            },
            "outputs": [],
            "source": [
                "def transform_baseball_data(df):\n",
                "    ###\n",
                "    ### YOUR CODE HERE\n",
                "    ###\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "To test your solution we have provided solution for the dataframe `baseball_test` \n",
                "\n",
                "**Note**: The below test case is designed just to help you debug. "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "nbgrader": {
                    "grade": true,
                    "grade_id": "transform_baseball_data_dummy",
                    "locked": true,
                    "points": "0",
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "# (0 Points) `transform_baseball_data_dummy`: Test cell\n",
                "from pandas.util.testing import assert_frame_equal\n",
                "\n",
                "df_ex2_soln_instructor = canonicalize_tibble(pd.read_csv(get_data_path('ex2_soln.csv'), parse_dates=['yearID']))\n",
                "df_ex2_soln_yours = canonicalize_tibble(transform_baseball_data(baseball_test))\n",
                "\n",
                "assert type(df_ex2_soln_yours) == type(df_ex2_soln_instructor), 'Your output does not return a pandas dataframe'\n",
                "assert_frame_equal(df_ex2_soln_instructor, df_ex2_soln_yours)\n",
                "\n",
                "print('Passed!')\n",
                "del df_ex2_soln_instructor\n",
                "del df_ex2_soln_yours"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "Testing on original dataframe"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "nbgrader": {
                    "grade": true,
                    "grade_id": "transform_baseball_data",
                    "locked": true,
                    "points": "3",
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "# (3 Points) `transform_baseball_data`: Test cell\n",
                "assert tibbles_are_equivalent(baseball, 1828659959833542576), \"Tibbles don't match!\" \n",
                "print(\"Passed!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "Let's transform the original dataframe `baseball`"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "baseball_test = transform_baseball_data(baseball_test)\n",
                "baseball = transform_baseball_data(baseball)\n",
                "baseball.shape"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "## Faster matrix products\n",
                "\n",
                "Now, we're going to change direction just a little. Don't worry, you don't need to know anything conceptual about what we're about to do; all you need to do is think of a faster way to apply the formula to generate its output based on the course material that's already been covered.\n",
                "\n",
                "One way of calculating the variance matrix $\\Sigma$ of a dataset is given by the formula\n",
                "\n",
                "$$\\Sigma=E(XX^T)-\\mu\\mu^T$$\n",
                "\n",
                "where $X$ is an $n \\times m$ matrix containing each data point and $\\mu$ is an $n \\times m$ matrix containing the column means of those data points.\n",
                "\n",
                "For this exercise, we will simply be calculating the parameter given to the expectation $E(\\cdot)$ function, $XX^T$. You can see in the cell below that this has already been done for you, but your task will be to figure out how to run `X.dot(X.T)` faster than we did.\n",
                "\n",
                "First, run the code cell below to establish an estimate time for the output."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "import numpy as np\n",
                "import timeit\n",
                "\n",
                "X = baseball[[x for x in baseball.columns if x not in ['playerID','yearID']]].values\n",
                "\n",
                "print(\"Matrix X is of size {}\".format(X.shape))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "inputHidden": false,
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "outputHidden": false,
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "def slow_calc(X):\n",
                "    return X.dot(X.T)\n",
                "\n",
                "slow_time = timeit.timeit(\"slow_calc(X)\",setup=\"from __main__ import slow_calc, X\", number = 1)\n",
                "print(\"Your estimated time for X.dot(X.T) is \"+' {0:.4f}'.format(slow_time) + \" seconds.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "**Exercise 3** (5 points): Come up with a way to make the matrix-times-transpose function faster than `slow_calc(X)`. Implement your method as the function `fast_calc()`. To get the full 5 points, your method must be **2.5 times faster**. You can get partial credit: 3 points if your function is at least 2 times faster and 1 point if your function is at least 1.5 times faster.\n",
                "\n",
                "The input to `fast_calc` is of type `numpy.ndarray` and expected output is also of type `numpy.ndarray`\n",
                "\n",
                "**Note**: The variable named `number_of_runs` determines how many times `fast_calc` will be run against the timer. You may lower `number_of_runs` for debugging purposes, but must increase it to at least 5 to pass the test cell. You may also import libraries you would like to use.\n",
                "\n",
                "**The benchmarks for this question are set according to Vocareum environment.** You might get different results if you test on your system. So please test your results here.\n",
                "\n",
                "> This exercise requires some creativity in thinking about how to exploit structure present in the problem."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "collapsed": true
            },
            "outputs": [],
            "source": [
                "number_of_runs = 5\n",
                "\n",
                "def fast_calc(X):\n",
                "    ###\n",
                "    ### YOUR CODE HERE\n",
                "    ###\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Run this test to get on 1 point for a solution that is at least 1.5 times faster"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "nbgrader": {
                    "grade": true,
                    "grade_id": "speed_test_1",
                    "locked": true,
                    "points": "1",
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "# (1 point) `speed_test_1`: Test cell\n",
                "for i in range(5):\n",
                "    nrows = np.random.randint(5) + 1\n",
                "    ncols = np.random.randint(5) + 1\n",
                "    A = np.random.rand(nrows, ncols)\n",
                "    your_out = fast_calc(A)\n",
                "    instructor_out = slow_calc(A)\n",
                "    assert type(your_out) == type(A), \"Please return object of type {}\".format(type(A))\n",
                "    np.testing.assert_array_almost_equal(instructor_out, your_out, decimal = 5)\n",
                "\n",
                "slow_time = timeit.timeit(\"slow_calc(X)\",setup=\"from __main__ import slow_calc, X\", number = number_of_runs)\/number_of_runs\n",
                "student_time = timeit.timeit(\"fast_calc(X)\", setup=\"from __main__ import fast_calc, X\",number = number_of_runs)\/number_of_runs\n",
                "print(\"Your baseline time for X.dot(X.T) is \"+'{0:.4f}'.format(student_time)+\" seconds, which is \"+'{0:.2f}'.format(slow_time\/student_time)+ \" times faster than our method.\")\n",
                "assert student_time\/slow_time <= 0.75, \"Your solution isn't at least 1.5 times faster than our solution.\"\n",
                "assert number_of_runs >= 5, \"number_of_runs needs to be >=5 to pass this cell.\"\n",
                "\n",
                "print(\"Passed!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "Run this test to get 2 points for a solution that is at least 2 times faster"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "nbgrader": {
                    "grade": true,
                    "grade_id": "speed_test_2",
                    "locked": true,
                    "points": "2",
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "# (2 point) `speed_test_2`: Test cell\n",
                "for i in range(5):\n",
                "    nrows = np.random.randint(5) + 1\n",
                "    ncols = np.random.randint(5) + 1\n",
                "    A = np.random.rand(nrows, ncols)\n",
                "    your_out = fast_calc(A)\n",
                "    instructor_out = slow_calc(A)\n",
                "    assert type(your_out) == type(A), \"Please return object of type {}\".format(type(A))\n",
                "    np.testing.assert_array_almost_equal(instructor_out, your_out, decimal = 5)\n",
                "\n",
                "slow_time = timeit.timeit(\"slow_calc(X)\",setup=\"from __main__ import slow_calc, X\", number = number_of_runs)\/number_of_runs\n",
                "student_time = timeit.timeit(\"fast_calc(X)\", setup=\"from __main__ import fast_calc, X\",number = number_of_runs)\/number_of_runs\n",
                "print(\"Your baseline time for X.dot(X.T) is \"+'{0:.4f}'.format(student_time)+\" seconds, which is \"+'{0:.2f}'.format(slow_time\/student_time)+ \" times faster than our method.\")\n",
                "assert student_time\/slow_time <= 0.50, \"Your solution isn't at least 2 times faster than our solution.\"\n",
                "assert number_of_runs >= 5, \"number_of_runs needs to be >=5 to pass this cell.\"\n",
                "\n",
                "print(\"Passed!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "Run this test to get 2 points for a solution that is at least 2.5 times faster"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "nbgrader": {
                    "grade": true,
                    "grade_id": "speed_test_3",
                    "locked": true,
                    "points": "2",
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "# (2 point) `speed_test_3`: Test cell\n",
                "for i in range(5):\n",
                "    nrows = np.random.randint(5) + 1\n",
                "    ncols = np.random.randint(5) + 1\n",
                "    A = np.random.rand(nrows, ncols)\n",
                "    your_out = fast_calc(A)\n",
                "    instructor_out = slow_calc(A)\n",
                "    assert type(your_out) == type(A), \"Please return object of type {}\".format(type(A))\n",
                "    np.testing.assert_array_almost_equal(instructor_out, your_out, decimal = 5)\n",
                "\n",
                "slow_time = timeit.timeit(\"slow_calc(X)\",setup=\"from __main__ import slow_calc, X\", number = number_of_runs)\/number_of_runs\n",
                "student_time = timeit.timeit(\"fast_calc(X)\", setup=\"from __main__ import fast_calc, X\",number = number_of_runs)\/number_of_runs\n",
                "print(\"Your baseline time for X.dot(X.T) is \"+'{0:.4f}'.format(student_time)+\" seconds, which is \"+'{0:.2f}'.format(slow_time\/student_time)+ \" times faster than our method.\")\n",
                "assert student_time\/slow_time <= 0.40, \"Your solution isn't at least 2.5 times faster than our solution.\"\n",
                "assert number_of_runs >= 5, \"number_of_runs needs to be >=5 to pass this cell.\"\n",
                "\n",
                "print(\"Passed!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "collapsed": true,
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "**Fin!** Remember to test your solutions by running them as the autograder will: restart the kernel and run all cells from \"top-to-bottom.\" Also remember to submit to the autograder; otherwise, you will **not** get credit for your hard work!"
            ]
        }
    ],
    "metadata": {
        "kernel_info": {
            "name": "python3"
        },
        "kernelspec": {
            "display_name": "Python 3.7",
            "language": "python",
            "name": "python37"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text\/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.7.5"
        },
        "nteract": {
            "version": "0.11.9"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}