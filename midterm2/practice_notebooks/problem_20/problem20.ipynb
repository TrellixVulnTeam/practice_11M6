{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "# Problem 20 (Midterm 2, Fall 2020): Human migration \u2014 where is everyone going? #\n",
                "\n",
                "_Version 1.1 (minor documentation edits from 1.0; no code changes)_\n",
                "\n",
                "This problem will exercise your knowledge of pandas, SQL, Numpy, and basic Python. It has **8** exercises, numbered 0 to 7. There are **18 available points.** However, to earn 100%, the threshold is just **15 points.** (Therefore, once you hit 15, you can stop. There is no extra credit for earning more than 15 points.)\n",
                "\n",
                "Each exercise builds logically on the previous one. **However, they may be completed independently.** That is, if you can't solve an exercise, you can still move on and try the next one.\n",
                "\n",
                "The point values of individual exercises are as follows:\n",
                "\n",
                "- Exercise 0: 2 points\n",
                "- Exercise 1: 2 point\n",
                "- Exercise 2: 2 points\n",
                "- Exercise 3: 2 points\n",
                "- Exercise 4: 3 points\n",
                "- Exercise 5: 3 points\n",
                "- Exercise 6: 1 point\n",
                "- Exercise 7: 3 points\n",
                "\n",
                "**Pro-tips.**\n",
                "- All test cells use **randomly generated inputs.** Therefore, try your best to write solutions that do not assume too much. To help you debug, when a test cell does fail, it will often tell you exactly what inputs it was using and what output it expected, compared to yours.\n",
                "- If you need a complex SQL query, remember that you can define one using a [triple-quoted (multiline) string](https:\/\/docs.python.org\/3.7\/tutorial\/introduction.html#strings).\n",
                "- If your program behavior seem strange, try resetting the kernel and rerunning everything.\n",
                "- If you mess up this notebook or just want to start from scratch, save copies of all your partial responses and use `Actions` $\\rightarrow$ `Reset Assignment` to get a fresh, original copy of this notebook. _(Resetting will wipe out any answers you've written so far, so be sure to stash those somewhere safe if you intend to keep or reuse them!)_\n",
                "- If you generate excessive output (e.g., from an ill-placed `print` statement) that causes the notebook to load slowly or not at all, use `Actions` $\\rightarrow$ `Clear Notebook Output` to get a clean copy. The clean copy will retain your code but remove any generated output. **However**, it will also **rename** the notebook to `clean.xxx.ipynb`. Since the autograder expects a notebook file with the original name, you'll need to rename the clean notebook accordingly.\n",
                "\n",
                "**Good luck!**"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "## Background ##\n",
                "\n",
                "In this problem, you'll analyze how people move from year-to-year within the United States. The main source of data is the US national tax collection agency, known as the Internal Revenue Service (IRS).\n",
                "\n",
                "When Americans pay their taxes, they are required to tell the IRS when they move. The IRS, in-turn, publishes this information as aggregated statistics, which can be used to help study migration patterns.\n",
                "\n",
                "Let's use these data to try to predict where Americans will live fifty years from now, in the year 2070. You might care about this question because you are thinking about where to expand your business, or because you are a policy planner concerned about how the natural pattern of human movement might interact with, say, the changing climate.\n",
                "\n",
                "In this notebook, you'll combine data from two sources:\n",
                "\n",
                "* The IRS's Tax Migration Data\n",
                "* Population data, including numbers of births and deaths, as collected by the US Census\n",
                "\n",
                "Your overall workflow will be as follows:\n",
                "\n",
                "1. You will use the tax migration data to model the flow of people year-after-year. Your model is a first-order Markov chain, just like PageRank (Notebook 11). The result of this analysis will be a probability transition matrix, which predicts what fraction of people living in one place will move to another.\n",
                "2. You will determine the population in different parts of the US today, using US Census data. The relative populations in each part of the US will become the \"initial distribution\" vector for PageRank.\n",
                "3. Combining (1) and (2) above, you can run PageRank to determine the \"steady-state distribution\" of who lives where in a future year (say, 2070).\n",
                "\n",
                "This analysis will allow you to compare the most populous places in the US today with those predicted for the year 2070."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "## Part 0: Setup ##"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "Run the following code cell to preload some standard modules you may find useful for this notebook."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "import sys\n",
                "print(f\"* Python version: {sys.version}\")\n",
                "\n",
                "import pandas as pd\n",
                "import numpy as np\n",
                "import scipy as sp"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "Run this code cell, which will load some tools needed by the test cells."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "scrolled": true,
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "###\n",
                "### AUTOGRADER TEST - DO NOT REMOVE\n",
                "###\n",
                "\n",
                "from testing_tools import load_db, get_db_schema, data_fn"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "## Dataset: IRS Tax Migration Data ##\n",
                "\n",
                "The first dataset you'll need is a SQLite database containing the tax migration data produced by the IRS. The following cell opens a connection to that database, which will be stored in a variable named `conn`."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "conn = load_db('irs-migration\/irs-migration.db')\n",
                "conn"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "The database has three tables, which were created using the following SQL commands:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "for k, table in enumerate(get_db_schema(conn)):\n",
                "    print(f'* [Table #{k}]', table[0])"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "Let's inspect the contents of each of these tables."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "### `States` table ###\n",
                "\n",
                "The first table, `States`, is a list of the US's fifty states (provinces). Each has a unique integer ID (`States.id`) and an abbreviated two-letter name (`States.name`). Here are the first few rows of this table:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "pd.read_sql_query('SELECT * FROM States LIMIT 5', conn)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "For example, the US state of Georgia has an ID of 13 and a two-letter abbreviated name, `\"GA\"`. (You don't need to know the names, only that they exist.)\n",
                "\n",
                "> This table includes the District of Columbia (`\"DC\"`), which is technically not a state. However, for the purpose of this notebook, [let's pretend](https:\/\/boundarystones.weta.org\/2020\/02\/12\/washington-taxation-without-representation-history)."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "### `Counties` table ###\n",
                "\n",
                "Each US state is further subdivided into many counties. These are stored in the table named `Counties`, whose first few rows are as follows:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "pd.read_sql_query('SELECT * FROM Counties LIMIT 5', conn)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "Each county has a unique integer ID and a name. The names are _not_ unique. For instance, there are 8 counties named `\"Fulton County\"`:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "pd.read_sql_query('SELECT * FROM Counties WHERE name=\"Fulton County\"', conn)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "To figure out to which state a given county belongs, you can do the following calculation. Let $i$ be the county ID. Then its state ID is $\\left\\lfloor \\frac{i}{10^3} \\right\\rfloor$. That is, take its county ID, divide it by 1,000, and keep the integer part. For instance, consider the Fulton County whose ID is `13121`. Its state is (13,121 \/ 1,000), whose integer part is 13. Recall that 13 is the state ID of `\"GA\"` (Georgia).\n",
                "\n",
                "Evidently, Georgia has 159 counties:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "pd.read_sql_query('SELECT * FROM Counties WHERE id >= 13000 AND id < 14000', conn)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "### Exercise 0 (2 points): `count_counties` ###\n",
                "\n",
                "Let `conn` be a connection to a database having tables named `States` and `Counties`, similar to the ones from the IRS database. Complete the function, `count_counties(conn)`, so that it does the following:\n",
                "\n",
                "- For each state, count how many counties it has\n",
                "- Return a _Python dictionary_ whose keys are states (taken from `States.name`) and whose values are the number of counties it contains.\n",
                "\n",
                "For example, if we ran `count_counties(conn)` on the connection object for the tax migration data, the dictionary it returns would include a key-value pair of `\"GA\": 159` (along with all the other states).\n",
                "\n",
                "> _Note:_ The test cell generates a database with _random_ data in it. Therefore, you should depend only on the structure of the tables and the fact of unique state IDs and unique county IDs, and not on any specific contents or values from the examples above."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "collapsed": true
            },
            "outputs": [],
            "source": [
                "def count_counties(conn):\n",
                "    ###\n",
                "    ### YOUR CODE HERE\n",
                "    ###\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Demo cell\n",
                "demo_counts = count_counties(conn)\n",
                "print(\"Found\", len(demo_counts), \"states.\")\n",
                "print(\"The state of 'GA' has\", demo_counts['GA'], \"counties.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "nbgrader": {
                    "grade": true,
                    "grade_id": "mt2_ex0__count_counties",
                    "locked": true,
                    "points": "2",
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "## Test cell: mt2_ex0__count_counties (2 points)\n",
                "\n",
                "###\n",
                "### AUTOGRADER TEST - DO NOT REMOVE\n",
                "###\n",
                "\n",
                "from testing_tools import mt2_ex0__check\n",
                "print(\"Testing...\")\n",
                "for trial in range(250):\n",
                "    mt2_ex0__check(count_counties)\n",
                "\n",
                "print(\"\\n(Passed!)\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "### `Flows` table: Migration flows ###\n",
                "\n",
                "The third table of the IRS data is the \"main attraction.\" It is named `Flows`, and here is a sample:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "scrolled": true,
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "pd.read_sql_query('SELECT * FROM Flows LIMIT 10', conn)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "For each year (the `'year'` column), it indicates how many addresses (`'num_returns'`) moved from one county (`'source'`) to another (`'dest'`). For example, the last row above shows that in 2013 there were 403 address changes from county 1001 to 1051. But, these source and destination counties can be the same, too, indicating that the address did not change or remained in the same county. For instance, row 5 above shows that in 2016 there were 17,484 addresses that remained in county 1001.\n",
                "\n",
                "If a year is missing for a particular (source, destination) pair, assume the number of returns that year is zero (0)."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "## Part 1: A Markov-chain model of migration ##\n",
                "\n",
                "Let's suppose that a reasonable model of how people move follows a first-order Markov process, similar to the one we saw in the PageRank algorithm of Topic 11.\n",
                "\n",
                "That is, let $i$ and $j$ be two counties. We model migration by saying that a person who lives in county $i$ will, each year, decide to move to county $j$ with probability $p_{i,j}$.\n",
                "\n",
                "To estimate the $p_{i,j}$ values, let's use the tax migration data stored in the `Flows` table. We'll then store these transition probabilities in a sparse matrix. The following four exercises, 1-4, will walk you through this process."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "### Exercise 1 (2 points): `sum_outflows` ###\n",
                "\n",
                "Let `conn` be a connection to a database having a table named `Flows`, just like the one above from the IRS database. Complete the function, `sum_outflows(conn)`, so that it does the following:\n",
                "\n",
                "- For each source (`Flows.source`), it sums the number of returns (`Flows.num_returns`) over all destinations and years.\n",
                "- It returns a pandas `DataFrame` with exactly two columns, one named `source` holding the source county ID, and another named `total_returns` holding the sum of all returns.\n",
                "\n",
                "For example, suppose the entire `Flows` table has just two sources, 13125 and 27077, with these entries:\n",
                "\n",
                "|    |   source |   dest |   year |   num_returns |   income_thousands |\n",
                "|---:|---------:|-------:|-------:|--------------:|-------------------:|\n",
                "|  0 |    13125 |  13125 |   2011 |           846 |              34655 |\n",
                "|  1 |    13125 |  13125 |   2012 |           846 |              36317 |\n",
                "|  2 |    13125 |  13125 |   2013 |           847 |              36034 |\n",
                "|  3 |    13125 |  13125 |   2014 |           845 |              38124 |\n",
                "|  4 |    13125 |  13125 |   2015 |           851 |              40282 |\n",
                "|  5 |    13125 |  13125 |   2016 |           801 |              40094 |\n",
                "|  6 |    13125 |  13125 |   2017 |           808 |              40933 |\n",
                "|  7 |    13125 |  13163 |   2011 |            16 |                466 |\n",
                "|  8 |    13125 |  13163 |   2012 |            11 |                361 |\n",
                "|  9 |    27077 |  27077 |   2011 |          1586 |              71766 |\n",
                "| 10 |    27077 |  27077 |   2012 |          1574 |              95614 |\n",
                "| 11 |    27077 |  27077 |   2013 |          1592 |              81399 |\n",
                "| 12 |    27077 |  27077 |   2014 |          1639 |              81974 |\n",
                "| 13 |    27077 |  27077 |   2015 |          1567 |              83778 |\n",
                "| 14 |    27077 |  27077 |   2016 |          1518 |              80534 |\n",
                "| 15 |    27077 |  27077 |   2017 |          1567 |              89557 |\n",
                "| 16 |    27077 |  27135 |   2011 |            17 |                532 |\n",
                "| 17 |    27077 |  27135 |   2012 |            19 |                622 |\n",
                "| 18 |    27077 |  27135 |   2015 |            24 |               1008 |\n",
                "| 19 |    27077 |  27135 |   2017 |            23 |                865 |\n",
                "\n",
                "Your function would return a data frame that looks like\n",
                "\n",
                "|    |   source | total_returns |\n",
                "|---:|---------:|--------------:|\n",
                "|  0 |    13125 |          5871 |\n",
                "|  1 |    27077 |         11126 |\n",
                "\n",
                "where the totals are taken over all destinations and years for each of the two sources.\n",
                "\n",
                "> _Note 0:_ The returned columns should have integer dtype.\n",
                ">\n",
                "> _Note 1:_ The test cell compares your result to the expected one using a function similar to `tibbles_are_equivalent`. Therefore, the order of returned sources does _not_ matter, but the counts must match exactly (since they are integers).\n",
                ">\n",
                "> _Note 2:_ Like Exercise 0, the test cell will use a randomly generated database as input."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "collapsed": true
            },
            "outputs": [],
            "source": [
                "def sum_outflows(conn):\n",
                "    ###\n",
                "    ### YOUR CODE HERE\n",
                "    ###\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Demo cell\n",
                "demo_sum_outflows = sum_outflows(conn)\n",
                "demo_sum_outflows[demo_sum_outflows['source'].isin({13125, 27077})]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "nbgrader": {
                    "grade": true,
                    "grade_id": "mt2_ex1__sum_outflows",
                    "locked": true,
                    "points": "2",
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "# Test cell: mt2_ex1__sum_outflows (1 point)\n",
                "\n",
                "from testing_tools import mt2_ex1__check\n",
                "print(\"Testing...\")\n",
                "for trial in range(250):\n",
                "    mt2_ex1__check(sum_outflows)\n",
                "\n",
                "print(\"\\n(Passed!)\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "**Transition probabilities.** Let's estimate the transition probability of moving from county $i$ to county $j$ by\n",
                "\n",
                "$$\n",
                "\\frac{\\mbox{total number of returns going from $i$ to $j$}}\n",
                "     {\\mbox{total number of returns leaving $i$}}.\n",
                "$$\n",
                "\n",
                "Here, \"total number\" means summed over all years. For instance, consider source 13125. Recall from Exercise 1 that it has a total number of returns of 5,871. The `Flows` data for 13125 has just two destinations, 13125 (itself) and 13163, as a query for `source=13125` shows:\n",
                "\n",
                "|    |   source |   dest |   year |   num_returns |   income_thousands |\n",
                "|---:|---------:|-------:|-------:|--------------:|-------------------:|\n",
                "|  0 |    13125 |  13125 |   2011 |           846 |              34655 |\n",
                "|  1 |    13125 |  13125 |   2012 |           846 |              36317 |\n",
                "|  2 |    13125 |  13125 |   2013 |           847 |              36034 |\n",
                "|  3 |    13125 |  13125 |   2014 |           845 |              38124 |\n",
                "|  4 |    13125 |  13125 |   2015 |           851 |              40282 |\n",
                "|  5 |    13125 |  13125 |   2016 |           801 |              40094 |\n",
                "|  6 |    13125 |  13125 |   2017 |           808 |              40933 |\n",
                "|  7 |    13125 |  13163 |   2011 |            16 |                466 |\n",
                "|  8 |    13125 |  13163 |   2012 |            11 |                361 |\n",
                "\n",
                "The total number of returns from 13125 to 13125 (i.e., itself), summed over all years, is 846+846+847+845+851+801+808=5,844. Therefore, its transition probability is (5,844 \/ 5,871) $\\approx$ 0.995. The total number of (13125, 13163) returns is just 16+11=27. Therefore, its transition probability is (27 \/ 5,871) $\\approx$ 0.005."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "### Exercise 2 (2 points): `estimate_probs` ###\n",
                "\n",
                "Let `conn` be a connection to a database having a table named `Flows` like the one from the IRS database. Complete the function, `estimate_probs(conn)`, below. This function should return a pandas `DataFrame` with three columns: `source` (taken from `Flows.source`), `dest` (taken from `Flows.dest`), and `prob`, which is the transition probability going from `source` to `dest`.\n",
                "\n",
                "From our earlier discussion, recall that the formula for the transition probability is\n",
                "\n",
                "$$\n",
                "\\frac{\\mbox{total number of returns going from $i$ to $j$}}\n",
                "     {\\mbox{total number of returns leaving $i$}}.\n",
                "$$\n",
                "\n",
                "For the example above, your function would return\n",
                "\n",
                "|   source |   dest |       prob |\n",
                "|---------:|-------:|-----------:|\n",
                "|    13125 |  13125 | 0.995401   |\n",
                "|    13125 |  13163 | 0.00459888 |\n",
                "\n",
                "> _Note:_ Your function should only return rows containing (`source`, `dest`) pairs that exist in the `Flows` table of the given `conn` database connection. As in previous exercises, the `conn` your function is given will contain randomly generated data.\n",
                ">\n",
                "> _Hint:_ If you use SQL to compute this table, note that dividing one integer by another produces a (truncated) integer result. Since probabilities should be floating-point values, you may need to cast your result explicitly, per this [Stackoverflow post](https:\/\/stackoverflow.com\/questions\/8305613\/converting-int-to-real-in-sqlite)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "collapsed": true
            },
            "outputs": [],
            "source": [
                "def estimate_probs(conn):\n",
                "    ###\n",
                "    ### YOUR CODE HERE\n",
                "    ###\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Demo cell\n",
                "demo_probs = estimate_probs(conn)\n",
                "demo_probs[demo_probs['source'] == 13125]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "nbgrader": {
                    "grade": true,
                    "grade_id": "mt2_ex2__estimate_probs",
                    "locked": true,
                    "points": "2",
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "# Test cell: mt2_ex2__estimate_probs (2 points)\n",
                "\n",
                "###\n",
                "### AUTOGRADER TEST - DO NOT REMOVE\n",
                "###\n",
                "\n",
                "from testing_tools import mt2_ex2__check\n",
                "print(\"Testing...\")\n",
                "for trial in range(250):\n",
                "    mt2_ex2__check(estimate_probs)\n",
                "\n",
                "print(\"\\n(Passed!)\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "**Converting logical county IDs to \"physical\" indices.** Recall that to construct a sparse matrix using Numpy\/Scipy, we will need to convert \"logical\" county IDs, which might be arbitrary, into \"physical\" indices that lie in the range [0, n-1] (inclusive), where `n` is the number of unique county IDs.\n",
                "\n",
                "In our case, the `Counties` table gives us a natural way to do that. Suppose we run the query,\n",
                "\n",
                "```sql\n",
                "SELECT * FROM Counties ORDER BY id\n",
                "```\n",
                "\n",
                "The output might look like the following:\n",
                "\n",
                "|      |    id | name                              |\n",
                "|-----:|------:|:----------------------------------|\n",
                "|    0 |  1001 | Autauga County                    |\n",
                "|    1 |  1003 | Baldwin County                    |\n",
                "|    2 |  1005 | Barbour County                    |\n",
                "| ...  |  ...  | ...                               |\n",
                "| 3141 | 56041 | Uinta County                      |\n",
                "| 3142 | 56043 | Washakie County                   |\n",
                "| 3143 | 56045 | Weston County                     |\n",
                "\n",
                "Observe that the _index_ values are numbered sequentially, from 0 to 3143. Thus, there are 3,144 unique county IDs. So, we can map the logical county ID `1001` to the physical integer index `0`, `1003` to `1`, ..., `56043` to `3142`, and `56045` to `3143`."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "### Exercise 3 (2 points): `map_counties` ###\n",
                "\n",
                "Let `conn` be a connection to a database having a table named `Counties` like the one from the IRS database. Complete the function, `map_counties(conn)`, so that it does the following.\n",
                "\n",
                "- Runs a query that orders the county IDs in ascending order, obtaining a pandas `DataFrame` like the one shown above.\n",
                "- Returns a _Python dictionary_ where each key is a logical integer county ID and the corresponding value is the physical integer index.\n",
                "\n",
                "For instance, when run on the IRS database, the output dictionary would contain the key-value pairs, `1001`: `0`, `1003`: `1`, ..., `56045`: `3143`.\n",
                "\n",
                "> _Note:_ The test cell generates a database with _random_ data in it. Therefore, you should depend only on the structure of the tables and the fact of unique state IDs and unique county IDs, and not on any specific contents or values from the examples above."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "collapsed": true
            },
            "outputs": [],
            "source": [
                "def map_counties(conn):\n",
                "    ###\n",
                "    ### YOUR CODE HERE\n",
                "    ###\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Demo cell\n",
                "\n",
                "demo_map_counties = map_counties(conn)\n",
                "\n",
                "for i in [1001, 1003, 1005, None, 56041, 56043, 56045]:\n",
                "    if i is None:\n",
                "        print(\"...\")\n",
                "        continue\n",
                "    print(i, \"==>\", demo_map_counties[i])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "nbgrader": {
                    "grade": true,
                    "grade_id": "mt2_ex3__map_counties",
                    "locked": true,
                    "points": "2",
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "# Test cell: mt2_ex3__map_counties (2 points)\n",
                "\n",
                "###\n",
                "### AUTOGRADER TEST - DO NOT REMOVE\n",
                "###\n",
                "\n",
                "from testing_tools import mt2_ex3__check\n",
                "print(\"Testing...\")\n",
                "for trial in range(250):\n",
                "    mt2_ex3__check(map_counties)\n",
                "\n",
                "print(\"\\n(Passed!)\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "### Exercise 4 (3 points) ###\n",
                "\n",
                "Suppose you are given the following two inputs:\n",
                "\n",
                "- `probs`: A data frame produced by Exercise 2, `estimate_probs`. This data frame has three columns, `source`, `dest`, and `prob`, where each row is the transition probability (`prob`) for a particular source-destination pair (`source`, `dest`).\n",
                "- `county_map`: A Python dictionary that maps logical county IDs to physical indices, per Exercise 3.\n",
                "\n",
                "Complete the function, `make_matrix(probs, county_map)`, so that it returns a probability transition matrix in Scipy's sparse COO format. (That is, you should use Scipy's [coo_matrix](https:\/\/docs.scipy.org\/doc\/scipy\/reference\/generated\/scipy.sparse.coo_matrix.html) function to construct this matrix.) This matrix should be `n`-by-`n`, where `n` is the number of unique county IDs, and it should only have nonzero entries where `probs` has an entry."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "collapsed": true
            },
            "outputs": [],
            "source": [
                "def make_matrix(probs, county_map):\n",
                "    from scipy.sparse import coo_matrix\n",
                "    assert isinstance(probs, pd.DataFrame)\n",
                "    assert isinstance(county_map, dict)\n",
                "    ###\n",
                "    ### YOUR CODE HERE\n",
                "    ###\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Demo cell\n",
                "demo_P = make_matrix(demo_probs, demo_map_counties)\n",
                "demo_n = max(demo_map_counties.values())+1\n",
                "print(\"* Shape:\", demo_P.shape, \"should equal\", (demo_n, demo_n))\n",
                "print(\"* Number of nonzeros:\", demo_P.nnz, \"should equal\", len(demo_probs))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "nbgrader": {
                    "grade": true,
                    "grade_id": "mt2_ex4__make_matrix",
                    "locked": true,
                    "points": "3",
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "# Test cell: mt2_ex4__make_matrix (3 points)\n",
                "\n",
                "###\n",
                "### AUTOGRADER TEST - DO NOT REMOVE\n",
                "###\n",
                "\n",
                "from testing_tools import mt2_ex4__check\n",
                "print(\"Testing...\")\n",
                "for trial in range(250):\n",
                "    mt2_ex4__check(make_matrix)\n",
                "\n",
                "print(\"\\n(Passed!)\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "## Part 2: Calculating the initial distribution ##\n",
                "\n",
                "Recall that to run a PageRank-style model, we need an initial probability distribution. In our case, we want to know what is the probability that a person in the US lives in a particular location (county ID). Exercise 5 estimates that probability using a new data source: the US Census Bureau's population statistics.\n",
                "\n",
                "The following code cell loads this data into a pandas `DataFrame` named `population` and inspects its contents."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "def load_pop_data(fn='census\/co-est2019-alldata.csv'):\n",
                "    pop = pd.read_csv(data_fn(fn), encoding='latin_1')\n",
                "    pop = pop[['STATE', 'COUNTY', 'POPESTIMATE2019', 'BIRTHS2019', 'DEATHS2019']]\n",
                "    pop = pop[pop['COUNTY'] > 0]\n",
                "    pop = pop[(pop['STATE'] != 15) & (pop['COUNTY'] != 5)]\n",
                "    return pop\n",
                "    \n",
                "population = load_pop_data()\n",
                "population.sample(5) # Show 5 randomly selected rows"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "This dataframe has one row per county. The county ID is split into two separate columns, one holding the state ID (`STATE`) and another holding the state-specific county sub-ID (`COUNTY`). So if the IRS county ID is 13125, you would see `13` for `STATE` and `125` for `COUNTY`.\n",
                "\n",
                "The remaining three columns show\n",
                "\n",
                "- the estimated number of people living in that county in 2019 (`POPESTIMATE2019`);\n",
                "- the number of births in that county in 2019 (`BIRTHS2019`);\n",
                "- and the number of deaths in that county in 2019 (`DEATHS2019`)."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "### Exercise 5 (3 points): `normalize_pop` ###\n",
                "\n",
                "Let `population` be a pandas `DataFrame` similar to the one defined above. That is, it has one row per county, and the columns `STATE`, `COUNTY`, and `POPESTIMATE2019`.\n",
                "\n",
                "Let `county_map` be a mapping of logical county IDs to physical indices, per Exercise 3.\n",
                "\n",
                "Complete the function, `normalize_pop(population)`, so that it returns a 1-D Numpy array such that\n",
                "\n",
                "1. there is one entry per county; and\n",
                "2. each element is the county's population divided by the _total_ population (sum of the `POPESTIMATE2019` column), stored as a floating-point value.\n",
                "\n",
                "For example, suppose `population` had the following five rows,\n",
                "\n",
                "|   |   STATE |   COUNTY |   POPESTIMATE2019 |   BIRTHS2019 |   DEATHS2019 |\n",
                "|--:|--------:|---------:|------------------:|-------------:|-------------:|\n",
                "| 0 |      47 |       69 |             25050 |          218 |          289 |\n",
                "| 1 |      50 |        1 |             36777 |          299 |          341 |\n",
                "| 2 |      26 |      117 |             63888 |          728 |          613 |\n",
                "| 3 |      55 |       23 |             16131 |          151 |          181 |\n",
                "| 4 |      22 |       99 |             53431 |          663 |          537 |\n",
                "\n",
                "Further suppose that `county_map == {47069: 2, 50001: 3, 26117: 1, 55023: 4, 22099: 0}`. The total population is 25050+36777+63888+16131+53431 = 195,277. Thus, `normalize_pop(population, county_map)` should return,\n",
                "\n",
                "```python\n",
                "array([0.27361645, 0.32716603, 0.12827932, 0.18833247, 0.08260573])\n",
                "```\n",
                "\n",
                "For instance, county 22099 is assigned the `0` index according to `county_map`. And since its estimated population in 2019 is 53431, its normalized population is 53431\/195277 $\\approx$ 0.2736...\n",
                "\n",
                "> _Note:_ Your function must _not_ modify the `population` data frame! If it needs to manipulate the input, then it should make a copy."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "collapsed": true
            },
            "outputs": [],
            "source": [
                "def normalize_pop(population, county_map):\n",
                "    assert isinstance(population, pd.DataFrame)\n",
                "    assert set(population.columns) == {'BIRTHS2019', 'COUNTY', 'DEATHS2019', 'POPESTIMATE2019', 'STATE'}\n",
                "    ###\n",
                "    ### YOUR CODE HERE\n",
                "    ###\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Demo cell\n",
                "demo_pop = population[population.apply(lambda row: (row['STATE'], row['COUNTY']) in [(47, 69), (50, 1), (26, 117), (55, 23), (22, 99)], axis=1)]\n",
                "demo_map = {47069: 2, 50001: 3, 26117: 1, 55023: 4, 22099: 0}\n",
                "normalize_pop(demo_pop, demo_map)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "nbgrader": {
                    "grade": true,
                    "grade_id": "mt2_ex5__normalize_pop",
                    "locked": true,
                    "points": "3",
                    "solution": false
                },
                "scrolled": false,
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "# Test cell: mt2_ex5__normalize_pop (3 points)\n",
                "\n",
                "###\n",
                "### AUTOGRADER TEST - DO NOT REMOVE\n",
                "###\n",
                "\n",
                "from testing_tools import mt2_ex5__check\n",
                "print(\"Testing...\")\n",
                "for trial in range(250):\n",
                "    mt2_ex5__check(normalize_pop)\n",
                "\n",
                "print(\"\\n(Passed!)\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "### Exercise 6 (1 point): Estimating the total future population ###\n",
                "\n",
                "The `population` dataframe also includes birth and death information. From that, let's try to estimate the _overall_ total population in future years, using the following procedure:\n",
                "\n",
                "- From the data frame, calculate the total number of people, the total number of births, and the total number of deaths in 2019. That is, we don't care about these values by location, but rather their overall sums.\n",
                "- Let $n_0$ be the total population in 2019, as calculated above.\n",
                "- Let $b_0$ be the total births in 2019. Define the _overall birth rate_ as $\\beta \\equiv \\frac{b_0}{n_0}$.\n",
                "- Let $d_0$ be the total deaths in 2019. Define the _overall death rate_ as $\\delta \\equiv \\frac{d_0}{n_0}$.\n",
                "- Assume that, overall, the birth and death rates remain constant over time. Then to estimate the total population $t$ years from now, calculate $n_t \\equiv n_0 (1 + \\beta - \\delta)^t$.\n",
                "\n",
                "Implement this procedure as the function, `estimate_pop(population, t)`, below. That is, it should take as input the population data (`population`, similar to Exercise 5) and target years from now (`t`). It should then return the corresponding value of $n_t$ as a floating-point number.\n",
                "\n",
                "For example, suppose `population` had exactly the following five rows:\n",
                "\n",
                "|   |   STATE |   COUNTY |   POPESTIMATE2019 |   BIRTHS2019 |   DEATHS2019 |\n",
                "|--:|--------:|---------:|------------------:|-------------:|-------------:|\n",
                "| 0 |      47 |       69 |             25050 |          218 |          289 |\n",
                "| 1 |      50 |        1 |             36777 |          299 |          341 |\n",
                "| 2 |      26 |      117 |             63888 |          728 |          613 |\n",
                "| 3 |      55 |       23 |             16131 |          151 |          181 |\n",
                "| 4 |      22 |       99 |             53431 |          663 |          537 |\n",
                "\n",
                "In this case, the total population is 195,277 people. If you follow the above procedure, you should get an estimated population at `t=50` years later of about `200237.73486678504`. _(You do not need to round your result explicitly.)_"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "collapsed": true
            },
            "outputs": [],
            "source": [
                "def estimate_pop(population, t):\n",
                "    assert isinstance(population, pd.DataFrame)\n",
                "    assert set(population.columns) == {'BIRTHS2019', 'COUNTY', 'DEATHS2019', 'POPESTIMATE2019', 'STATE'}\n",
                "    assert isinstance(t, int) and t >= 0\n",
                "    ###\n",
                "    ### YOUR CODE HERE\n",
                "    ###\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Demo cell\n",
                "demo_pop = population[population.apply(lambda row: (row['STATE'], row['COUNTY']) in [(47, 69), (50, 1), (26, 117), (55, 23), (22, 99)], axis=1)]\n",
                "estimate_pop(demo_pop, 50)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "nbgrader": {
                    "grade": true,
                    "grade_id": "mt2_ex6__estimate_pop",
                    "locked": true,
                    "points": "1",
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "# Test cell: mt2_ex6__estimate_pop (1 point)\n",
                "\n",
                "from testing_tools import mt2_ex6__check\n",
                "print(\"Testing...\")\n",
                "for trial in range(1000):\n",
                "    mt2_ex6__check(estimate_pop)\n",
                "\n",
                "print(\"\\n(Passed!)\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "## Part 3: Richest (per capita) counties ##\n",
                "\n",
                "The IRS tax data set includes information about income. While not a direct representation of \"wealth,\" let's treat it as an indicator and rank the counties by this reported income."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "**\"Income per return\" by county.** Quickly recall the structure of the `Flows` table:\n",
                "\n",
                "|    |   source |   dest |   year |   num_returns |   income_thousands |\n",
                "|---:|---------:|-------:|-------:|--------------:|-------------------:|\n",
                "|    |          |        |  ...   |               |                    |\n",
                "|  4 |    13125 |  13125 |   2015 |           851 |              40282 |\n",
                "|  5 |    13125 |  13125 |   2016 |           801 |              40094 |\n",
                "|  6 |    13125 |  13125 |   2017 |           808 |              40933 |\n",
                "|  7 |    13125 |  13163 |   2011 |            16 |                466 |\n",
                "|  8 |    13125 |  13163 |   2012 |            11 |                361 |\n",
                "|    |          |        |  ...   |               |                    |"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "The column named `\"income_thousands\"` is the total reported income in thousands of US dollars for all of the returns. For instance, in row 4 above, the total income in 2015 across all 851 returns filed (and staying within) county 13125 was 40,282,000 USD, which is about 47,334.90 USD per return.\n",
                "\n",
                "When the `\"source\"` and `\"dest\"` are the same, all of this income \"belongs\" to a given county. But what happens when they differ? For example, consider county 2068:"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "|    |   source |   dest |   year |   num_returns |   income_thousands |\n",
                "|---:|---------:|-------:|-------:|--------------:|-------------------:|\n",
                "|  0 |     2020 |   2068 |   2011 |            14 |                683 |\n",
                "|  1 |     2020 |   2068 |   2012 |            10 |                318 |\n",
                "|  2 |     2068 |   2068 |   2011 |           854 |              58637 |\n",
                "|  3 |     2068 |   2068 |   2012 |           842 |              59815 |\n",
                "|  4 |     2068 |   2068 |   2013 |           832 |              60200 |\n",
                "|  5 |     2068 |   2068 |   2014 |           855 |              67174 |\n",
                "|  6 |     2068 |   2068 |   2015 |           866 |              66860 |\n",
                "|  7 |     2068 |   2068 |   2016 |           837 |              61617 |\n",
                "|  8 |     2068 |   2068 |   2017 |           858 |              65833 |\n",
                "|  9 |     2068 |   2170 |   2011 |            10 |                600 |\n",
                "| 10 |     2068 |   2170 |   2012 |            11 |                793 |\n",
                "| 11 |     2068 |   2090 |   2012 |            24 |               1433 |\n",
                "| 12 |     2068 |   2090 |   2015 |            21 |               1970 |\n",
                "| 13 |     2068 |   2090 |   2016 |            20 |               1661 |\n",
                "| 14 |     2068 |   2090 |   2017 |            23 |               1223 |\n",
                "| 15 |     2068 |   2020 |   2012 |            20 |                890 |\n",
                "| 16 |     2090 |   2068 |   2011 |            20 |                794 |\n",
                "| 17 |     2090 |   2068 |   2012 |            18 |               1098 |\n",
                "| 18 |     2122 |   2068 |   2011 |            10 |                325 |\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "Rows 2-8 have the same values for `\"source\"` and `\"dest\"`. Let's call these **self-flows.** But rows 0-1 and 16-18 have only `\"dest\"` values as 2068, making them **inflows** from other counties into 2068; and rows 9-15 are have only `\"source\"`  equal to 2068, making them **outflows** from 2068 to other counties."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "Thus, to estimate the total income per return in a given county, let's use the following formula. It keeps all self-flow income, but \"splits the difference\" for inflow and outflow income:\n",
                "$$\n",
                "\\mbox{(total income per return)} = \n",
                "\\frac{\\mbox{(total self-flow income)} + \\frac{1}{2}\\left[\\mbox{(total inflow income)} + \\mbox{(total outflow income)}\\right]}\n",
                "     {\\mbox{(total self-flow returns)} + \\frac{1}{2}\\left[\\mbox{(total inflow returns)} + \\mbox{(total outflow returns)}\\right]}\n",
                "$$"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "For the county 2068 example, this value is\n",
                "$$\n",
                "\\frac{440\\,136\\,000 + 4\\,285\\,000 + 1\\,609\\,000}\n",
                "     {5\\,944 + 36 + 64.5}\n",
                "\\approx 73\\,791.05 \\mbox{ USD}.\n",
                "$$"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "### Exercise 7 (3 points): Ranking counties by income per return ### \n",
                "\n",
                "Given a connection `conn` to a database containing a tax `Flows` table, complete the function `calc_ipr(conn)` to calculate the income per return for each county.\n",
                "\n",
                "In particular, it should return a pandas `DataFrame` with one row per unique county ID and the following columns:\n",
                "\n",
                "- `'county_id'`: County IDs\n",
                "- `'ipr'`: Income per return, in _dollars_, as floating-point values.\n",
                "\n",
                "> _Note 0:_ Regarding the `'ipr'` column, recall that the `'income_thousands'` column of the `Flows` table uses _thousands_ of dollars. So if it has the value, `123`, that should be treated and converted to `123,000`.\n",
                ">\n",
                "> _Note 1:_ Note that some counties might not have inflows or outflows. So, you'll need to be able to handle that case."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "collapsed": true
            },
            "outputs": [],
            "source": [
                "def calc_ipr(conn):\n",
                "    ###\n",
                "    ### YOUR CODE HERE\n",
                "    ###\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Demo cell 0: Should get approximately 73791.05 for county 2068\n",
                "income = calc_ipr(conn)\n",
                "income[income['county_id'] == 2068]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Demo cell 1: print top 5 counties by `ipr`\n",
                "income.sort_values(by='ipr', ascending=False).head(5)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "nbgrader": {
                    "grade": true,
                    "grade_id": "mt2_ex7__calc_ipr",
                    "locked": true,
                    "points": "3",
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "# Test cell: mt2_ex7__calc_ipr (3 points)\n",
                "\n",
                "###\n",
                "### AUTOGRADER TEST - DO NOT REMOVE\n",
                "###\n",
                "\n",
                "from testing_tools import mt2_ex7__check\n",
                "print(\"Testing...\")\n",
                "for trial in range(5):\n",
                "    mt2_ex7__check(calc_ipr)\n",
                "\n",
                "print(\"\\n(Passed!)\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "## Part 4: Putting it all together ##\n",
                "\n",
                "We are now ready to put it all together, and see how migration might affect which parts of the US are most populous."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "**Running \"PageRank.\"** Your initial distribution (Exercise 5) provides one ranking of the cities. If we run PageRank using the probability transition matrix that models migration (Exercises 2-4), we'll get a new ranking.\n",
                "\n",
                "This code cell runs PageRank. (You should recognize it from Notebook 11!) It gives you the final results in a `DataFrame` named `rankings`."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "from testing_tools import load_pickle, load_json\n",
                "\n",
                "# Run PageRank\n",
                "P = load_pickle('matrix.pickle')\n",
                "x_0 = load_pickle('dist0.pickle') # initial distribution\n",
                "x = x_0.copy() # holds final distribution\n",
                "for _ in range(50):\n",
                "    x = P.T.dot(x)\n",
                "x_final = x.copy()\n",
                "\n",
                "# Build DataFrame\n",
                "def get_ranking(x):\n",
                "    k = np.argsort(x)\n",
                "    r = np.empty(len(x), dtype=int)\n",
                "    r[k] = np.arange(len(x))\n",
                "    return r\n",
                "\n",
                "# Get population ranking\n",
                "county_map = load_json('map_counties.json') # county IDs -> physical indices\n",
                "inv_county_map = {v: k for k, v in county_map.items()} # physical indices -> county IDs\n",
                "\n",
                "rankings = pd.DataFrame({'county_id': [inv_county_map[k] for k in range(len(county_map))],\n",
                "                         'rank_2019': get_ranking(-x_0), 'x_2019': x_0,\n",
                "                         'rank_2070': get_ranking(-x_final), 'x_2070': x_final})\n",
                "rankings['county_id'] = rankings['county_id'].astype(int)\n",
                "\n",
                "# Add income data\n",
                "top_incomes = pd.read_csv(data_fn('incomes.csv'))\n",
                "top_incomes['rank_ipr'] = top_incomes.index\n",
                "\n",
                "# Construct location metadata\n",
                "locations = pd.read_sql_query(\"\"\"SELECT Counties.id AS county_id,\n",
                "                                        Counties.name||', '||States.name AS name\n",
                "                                 FROM Counties, States\n",
                "                                 WHERE Counties.id\/1000 == States.id\"\"\", conn)\n",
                "\n",
                "# Merge\n",
                "rankings = rankings.merge(locations, how='left', on='county_id') \\\n",
                "                   .merge(top_incomes, how='left', on='county_id') \\\n",
                "                   [['county_id', 'name', 'rank_2019', 'rank_2070', 'x_2019', 'x_2070', 'ipr', 'rank_ipr']]\n",
                "rankings.head()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "For each county (`county_id`), it shows the initial ranking by population in the year 2019 (`rank_2019`), as well as the predicted ranking in the year 2070. It also merges in the income-per-return measure, and adds a new column, called `rank_ipr`, that includes the rank of the county by income-per-return. (A rank of 0 would mean that county has the highest income-per-return in the entire country.)\n",
                "\n",
                "Let's take a look at the top 10 counties by their Year 2070 ranking:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "# View Top 10 according to their year 2070 rankings:\n",
                "rankings.sort_values(by='rank_2070').head(10)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "You should observe that counties in the top 6 (ranks 0-5) remain there, but the ordering changes; and three counties that previously were not in the top 10 now join those ranks (Clark County, NV; King County, WA; and Tarrant County, TX)."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "**Fin!** You\u2019ve reached the end of Midterm 2. Don\u2019t forget to restart and run all cells again to make sure it\u2019s all working when run in sequence; and make sure your work passes the submission process. Good luck!"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "**Epilogue.** The analysis in this notebook is very rough, as there are many caveats in how to interpret the IRS's data. But think of it as a starting point for more serious exploration of human migration.\n",
                "\n",
                "For instance, recall the ranking by income-per-return (IPR) in Exercise 7. In the final rankings, the counties in the top 10 are relatively rich (recall the IPR ranks are in the low hundreds, whereas there are over 3,000 counties). However, they are not \"too rich.\" Perhaps it is easier to move to regions where incomes are higher than where one comes from, but not so high that one cannot afford to move at all. A deeper analysis of income and mobility would certainly be fun!\n",
                "\n",
                "The phenomenon of migration has even deeper implications. Indeed, this problem was inspired by [this article from the New York Times on human migration and climate change](https:\/\/www.nytimes.com\/interactive\/2020\/07\/23\/magazine\/climate-migration.html), which you might enjoy reading now that your exam is over.\n",
                "\n",
                "Data sources for this notebook:\n",
                "- US Census Bureau: [Population data](https:\/\/www.census.gov\/data\/datasets\/time-series\/demo\/popest\/2010s-counties-total.html)\n",
                "- US Internal Revenue Service [Tax migration data](https:\/\/www.irs.gov\/statistics\/soi-tax-stats-migration-data)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3 [3.7]",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text\/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.7.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}